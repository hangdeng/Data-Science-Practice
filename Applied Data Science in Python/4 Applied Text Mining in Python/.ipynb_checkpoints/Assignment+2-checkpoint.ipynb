{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255018"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_one():\n",
    "    \n",
    "    return len(nltk.word_tokenize(moby_raw)) # or alternatively len(text1)\n",
    "\n",
    "example_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20754"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_two():\n",
    "    \n",
    "    return len(set(nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hdeng8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16899"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "def example_three():\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "\n",
    "    return len(set(lemmatized))\n",
    "\n",
    "example_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08138249064771899"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "    \n",
    "    return example_two()/example_one() # Your answer here\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4125199005560392"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    \n",
    "    \n",
    "    return (text1.count('whale')+text1.count('Whale'))/example_one()*100# Your answer here\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2111),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "def answer_three():\n",
    "    dist=nltk.FreqDist(text1)\n",
    "    token_sorted=sorted(dist.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return token_sorted[:20] # nltk.FreqDist(moby_tokens).most_common(20) # Your answer here\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return an alphabetically sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Adios\",\n",
       " \"'Better\",\n",
       " \"'Canallers\",\n",
       " \"'Cross\",\n",
       " \"'Excuse\",\n",
       " \"'Halloa\",\n",
       " \"'Lakeman\",\n",
       " \"'Lively\",\n",
       " \"'Point\",\n",
       " \"'Proceed\",\n",
       " \"'Shall\",\n",
       " \"'Stern\",\n",
       " \"'There\",\n",
       " \"'Though\",\n",
       " \"'Thunder\",\n",
       " \"'Twill\",\n",
       " \"'Where\",\n",
       " \"'balmed\",\n",
       " \"'dention\",\n",
       " \"'gainst\",\n",
       " \"'right\",\n",
       " \"'specially\",\n",
       " \"'stead\",\n",
       " \"'straight\",\n",
       " \"'there\",\n",
       " \"'vomited\",\n",
       " \"'where\",\n",
       " '*Bible',\n",
       " '*Partly',\n",
       " '*Quoin',\n",
       " '*Since',\n",
       " '*Though',\n",
       " '10,440',\n",
       " '10,800',\n",
       " '13,000',\n",
       " '144,000',\n",
       " '150,000',\n",
       " '20,000',\n",
       " '20,000,000',\n",
       " '25,000',\n",
       " '4,000,000',\n",
       " '400,000',\n",
       " '550,000',\n",
       " '60,000',\n",
       " '7,000,000',\n",
       " '72,000',\n",
       " 'A-PLENTY',\n",
       " 'ACCOUNT',\n",
       " 'ADDITIONAL',\n",
       " 'ADVANCING',\n",
       " 'ADVENTURES',\n",
       " 'AFFGHANISTAN',\n",
       " 'AFRICA',\n",
       " 'AGAINST',\n",
       " 'ALFRED',\n",
       " 'ALGERINE',\n",
       " 'AMERICA',\n",
       " 'ANCHORS',\n",
       " 'ANGLO-SAXON',\n",
       " 'ANIMAL',\n",
       " 'ANNALS',\n",
       " 'ANOTHER',\n",
       " 'APOLOGY',\n",
       " 'APPLICATION',\n",
       " 'APPROACHING',\n",
       " 'ARCTIC',\n",
       " 'AROUND',\n",
       " 'ASCENDING',\n",
       " 'ASPECT',\n",
       " 'ATTACK',\n",
       " 'ATTACKED',\n",
       " 'ATTITUDES',\n",
       " 'AUGUST',\n",
       " 'AUTHOR',\n",
       " 'Abashed',\n",
       " 'Abednego',\n",
       " 'Abjectus',\n",
       " 'Aboard',\n",
       " 'Abominable',\n",
       " 'Abraham',\n",
       " 'Academy',\n",
       " 'Accessory',\n",
       " 'According',\n",
       " 'Accordingly',\n",
       " 'Accursed',\n",
       " 'Achilles',\n",
       " 'Actium',\n",
       " 'Acushnet',\n",
       " 'Admiral',\n",
       " 'Admirals',\n",
       " 'Advance',\n",
       " 'Advancement',\n",
       " 'Adventures',\n",
       " 'Adverse',\n",
       " 'Advocate',\n",
       " 'Affected',\n",
       " 'Affidavit',\n",
       " 'Affrighted',\n",
       " 'Africa',\n",
       " 'African',\n",
       " 'Africans',\n",
       " 'Afterwards',\n",
       " 'Against',\n",
       " 'Agassiz',\n",
       " \"Ahab's\",\n",
       " 'Ahasuerus',\n",
       " 'Ahaz-dial',\n",
       " 'Alabama',\n",
       " 'Aladdin',\n",
       " 'Alarmed',\n",
       " 'Albatross',\n",
       " 'Albemarle',\n",
       " 'Albert',\n",
       " 'Albicore',\n",
       " 'Albino',\n",
       " 'Aldrovandi',\n",
       " 'Aldrovandus',\n",
       " 'Alexander',\n",
       " 'Alexanders',\n",
       " 'Alfred',\n",
       " 'Algerine',\n",
       " 'Algiers',\n",
       " 'Alleghanian',\n",
       " 'Alleghanies',\n",
       " 'Almanack',\n",
       " 'Almighty',\n",
       " 'Almost',\n",
       " 'Aloft.',\n",
       " 'Already',\n",
       " 'Ambergriese',\n",
       " 'Ambergris',\n",
       " 'Amelia',\n",
       " 'America',\n",
       " 'American',\n",
       " 'Americans',\n",
       " 'Americas',\n",
       " 'Amittai',\n",
       " 'Amsterdam',\n",
       " 'Anacharsis',\n",
       " 'Anatomist',\n",
       " 'Andrew',\n",
       " 'Andromeda',\n",
       " 'Angelo',\n",
       " 'Angels',\n",
       " 'Animated',\n",
       " 'Annawon',\n",
       " 'Anomalous',\n",
       " 'Another',\n",
       " 'Answer',\n",
       " 'Antarctic',\n",
       " 'Antilles',\n",
       " \"Antiochus's\",\n",
       " 'Antony',\n",
       " 'Antwerp',\n",
       " 'Anyhow',\n",
       " 'Anything',\n",
       " 'Anyway',\n",
       " 'Apollo',\n",
       " 'Apoplexy',\n",
       " 'Applied',\n",
       " 'Aquarius',\n",
       " 'Archbishop',\n",
       " 'Arched',\n",
       " 'Archer',\n",
       " 'Archipelagoes',\n",
       " 'Arctic',\n",
       " 'Arethusa',\n",
       " 'Argo-Navis',\n",
       " 'Aristotle',\n",
       " 'Arkansas',\n",
       " 'Arkite',\n",
       " 'Armada',\n",
       " 'Arnold',\n",
       " 'Aroostook',\n",
       " 'Around',\n",
       " 'Arrayed',\n",
       " 'Arrived',\n",
       " 'Arsacidean',\n",
       " 'Arsacides',\n",
       " 'Artedi',\n",
       " 'Articles',\n",
       " 'Ashantee',\n",
       " 'Ashore',\n",
       " 'Asiatic',\n",
       " 'Asiatics',\n",
       " 'Asphaltites',\n",
       " 'Assaulted',\n",
       " 'Assume',\n",
       " 'Assuming',\n",
       " 'Assuredly',\n",
       " 'Assyrian',\n",
       " 'Astern',\n",
       " 'Astronomy',\n",
       " 'Atlantic',\n",
       " 'Atlantics',\n",
       " 'Attached',\n",
       " 'Attend',\n",
       " 'August',\n",
       " 'Australia',\n",
       " 'Australian',\n",
       " 'Austrian',\n",
       " 'Author',\n",
       " 'Authors',\n",
       " 'Auto-da-Fe',\n",
       " 'Availing',\n",
       " 'Avatar',\n",
       " 'Azores',\n",
       " 'BALEINE',\n",
       " 'BALLENA',\n",
       " 'BATTLE',\n",
       " 'BEFORE',\n",
       " 'BELFAST',\n",
       " 'BENNETT',\n",
       " 'BERMUDAS',\n",
       " 'BETWEEN',\n",
       " 'BEWARE',\n",
       " 'BIOGRAPHY',\n",
       " 'BLACKSMITH',\n",
       " 'BLACKSTONE',\n",
       " 'BLOODY',\n",
       " 'BOUTON',\n",
       " 'BRACTON',\n",
       " 'BREACH',\n",
       " 'BREAKERS',\n",
       " 'BREAKWATER',\n",
       " 'BROTHER',\n",
       " 'BROWNE',\n",
       " \"BROWNE'S\",\n",
       " \"BURKE'S\",\n",
       " 'BUSILY',\n",
       " 'Babylon',\n",
       " 'Babylonian',\n",
       " 'Bachelor',\n",
       " 'Baden-Baden',\n",
       " 'Balaene',\n",
       " 'Baliene',\n",
       " 'Baling',\n",
       " 'Baltic',\n",
       " 'Baltimore',\n",
       " 'Bamboo-Town',\n",
       " 'Barbary',\n",
       " 'Bare-headed',\n",
       " 'Bargain',\n",
       " 'Barrens',\n",
       " 'Bartholomew',\n",
       " 'Bashaw',\n",
       " 'Bashee',\n",
       " 'Basilosaurus',\n",
       " 'Bastille',\n",
       " 'Battering-Ram',\n",
       " 'Battery',\n",
       " 'Because',\n",
       " 'Becket',\n",
       " 'Bedford',\n",
       " 'Beelzebub',\n",
       " 'Befooled',\n",
       " 'Before',\n",
       " 'Begone',\n",
       " 'Behold',\n",
       " 'Behring',\n",
       " 'Belated',\n",
       " 'Belial',\n",
       " 'Believe',\n",
       " 'Belisarius',\n",
       " 'Bell-boy',\n",
       " 'Bellies',\n",
       " 'Beloved',\n",
       " 'Belshazzar',\n",
       " 'Belubed',\n",
       " 'Bendigoes',\n",
       " 'Beneath',\n",
       " 'Bengal',\n",
       " 'Benjamin',\n",
       " 'Bennett',\n",
       " 'Bentham',\n",
       " 'Berkshire',\n",
       " 'Berlin',\n",
       " 'Bernard',\n",
       " 'Besides',\n",
       " 'Bestow',\n",
       " 'Bethink',\n",
       " 'Better',\n",
       " 'Between',\n",
       " 'Beware',\n",
       " 'Beyond',\n",
       " 'Bibles',\n",
       " 'Bibliographical',\n",
       " 'Bildad',\n",
       " 'Biographical',\n",
       " 'Birmah',\n",
       " 'Bishop',\n",
       " 'Blacksmith',\n",
       " 'Blackstone',\n",
       " 'Blanche',\n",
       " 'Blanco',\n",
       " 'Blang-whang',\n",
       " 'Blanket',\n",
       " 'Blinding',\n",
       " 'Blocksburg',\n",
       " 'Bloody',\n",
       " 'Bobbing',\n",
       " 'Bolivia',\n",
       " 'Bombay',\n",
       " 'Bonapartes',\n",
       " 'Bonneterre',\n",
       " 'Booble',\n",
       " 'Boomer',\n",
       " 'Bordeaux',\n",
       " 'Borean',\n",
       " 'Borneo',\n",
       " 'Boston',\n",
       " 'Bottle',\n",
       " 'Bottle-Nose',\n",
       " 'Bottom',\n",
       " 'Bourbons',\n",
       " 'Bouton',\n",
       " 'Bouton-de-Rose',\n",
       " 'Bouton-de-Rose-bud',\n",
       " 'Bouton-de-Roses',\n",
       " 'Bowditch',\n",
       " 'Brahma',\n",
       " 'Brahmins',\n",
       " 'Brandreth',\n",
       " 'Brazil',\n",
       " 'Breakfast',\n",
       " 'Bremen',\n",
       " 'Bridge',\n",
       " 'Brighggians',\n",
       " 'Bright',\n",
       " 'Brisson',\n",
       " 'Britain',\n",
       " 'British',\n",
       " 'Britons',\n",
       " 'Broad-nosed',\n",
       " 'Broadway',\n",
       " 'Brother',\n",
       " 'Browne',\n",
       " 'Buckets',\n",
       " 'Buffalo',\n",
       " 'Bulkington',\n",
       " 'Bulwarks',\n",
       " 'Bunger',\n",
       " 'Bungle',\n",
       " 'Bunyan',\n",
       " 'Buoyed',\n",
       " 'Burkes',\n",
       " 'Burton',\n",
       " 'Burtons',\n",
       " 'Business',\n",
       " 'Butchers',\n",
       " 'Butler',\n",
       " 'By-laws',\n",
       " 'Byward',\n",
       " 'CABIN-GANGWAY',\n",
       " 'CABINET',\n",
       " 'CAPTAIN',\n",
       " 'CAPTAINS',\n",
       " 'CAPTORS',\n",
       " 'CARPENTER',\n",
       " 'CATCHES',\n",
       " 'CAULKING',\n",
       " 'CHAPTERS',\n",
       " 'CHARLES',\n",
       " 'CHEERLY',\n",
       " 'CHEEVER',\n",
       " 'CHORUS',\n",
       " 'CHRONICLER',\n",
       " 'CIRCUMNAVIGATION',\n",
       " 'CLOSES',\n",
       " 'CLUSTERS',\n",
       " 'COFFIN',\n",
       " 'COLEMAN',\n",
       " 'COLNETT',\n",
       " 'COMMERCIAL',\n",
       " 'COMMODORE',\n",
       " 'COMSTOCK',\n",
       " 'CONTESTED',\n",
       " 'CONTINUES',\n",
       " 'CONVERSATIONS',\n",
       " \"COOK'S\",\n",
       " 'COOPER',\n",
       " 'COWLEY',\n",
       " 'COWPER',\n",
       " \"CROW'S-NEST\",\n",
       " \"CROW'S-NESTS\",\n",
       " 'CRUISE',\n",
       " 'CRUISING-GROUND',\n",
       " 'CRUIZE',\n",
       " 'CURRENTS',\n",
       " 'CUVIER',\n",
       " 'Cabaco',\n",
       " 'Cabin-Table',\n",
       " 'Cachalot',\n",
       " 'Caesar',\n",
       " 'Caesarian',\n",
       " 'Calais',\n",
       " 'Californian',\n",
       " 'Callao',\n",
       " 'Cambyses',\n",
       " 'Campagna',\n",
       " \"Can'st\",\n",
       " 'Canaan',\n",
       " 'Canada',\n",
       " 'Canadian',\n",
       " 'Canaller',\n",
       " 'Canallers',\n",
       " 'Canals',\n",
       " 'Canaris',\n",
       " 'Cancer',\n",
       " 'Candles',\n",
       " 'Cannibal',\n",
       " 'Cannibals',\n",
       " 'Cannon',\n",
       " 'Canterbury',\n",
       " \"Cap'ain\",\n",
       " 'Cape-Cod-man',\n",
       " 'Cape-Down',\n",
       " 'Cape-Horner',\n",
       " 'Cape-Town',\n",
       " 'Capricornus',\n",
       " \"Captain's\",\n",
       " 'Captains',\n",
       " 'Capting',\n",
       " 'Caramba',\n",
       " 'Careful',\n",
       " 'Carefully',\n",
       " 'Carpenter',\n",
       " 'Carpet-Bag',\n",
       " 'Carrol',\n",
       " 'Carson',\n",
       " 'Carthage',\n",
       " 'Caryatid',\n",
       " 'Cassock',\n",
       " 'Castaway',\n",
       " 'Castle',\n",
       " 'Categut',\n",
       " 'Cathedral',\n",
       " 'Catholic',\n",
       " 'Catskill',\n",
       " 'Cattegat',\n",
       " 'Caught',\n",
       " 'Cellini',\n",
       " 'Central',\n",
       " 'Certain',\n",
       " 'Certainly',\n",
       " 'Cervantes',\n",
       " 'Cetacea',\n",
       " 'Cetacean',\n",
       " 'Cetology',\n",
       " 'Ceylon',\n",
       " 'Chaldee',\n",
       " 'Champagne',\n",
       " 'Champollion',\n",
       " 'Channel',\n",
       " 'Chapel',\n",
       " 'Charing',\n",
       " 'Charity',\n",
       " 'Charlemagne',\n",
       " 'Charley',\n",
       " 'Chartering',\n",
       " 'Chase.',\n",
       " 'Cheever',\n",
       " 'Cherries',\n",
       " 'Chestnut',\n",
       " 'Childe',\n",
       " 'Chilian',\n",
       " 'Chinese',\n",
       " 'Chowder',\n",
       " 'Christ',\n",
       " 'Christendom',\n",
       " 'Christian',\n",
       " 'Christianity',\n",
       " 'Christians',\n",
       " 'Christmas',\n",
       " 'Church',\n",
       " 'Cinque',\n",
       " 'Circassian',\n",
       " 'Circumambulate',\n",
       " 'Cistern',\n",
       " 'Civitas',\n",
       " 'Clearing',\n",
       " 'Cleopatra',\n",
       " 'Cleveland',\n",
       " 'Clifford',\n",
       " 'Clinging',\n",
       " 'Clootz',\n",
       " 'Closing',\n",
       " 'Cock-Lane',\n",
       " 'Cockatoo',\n",
       " 'Coenties',\n",
       " 'Coffin',\n",
       " 'Coffins',\n",
       " 'Cognac',\n",
       " 'Coke-upon-Littleton',\n",
       " 'Coleman',\n",
       " 'Coleridge',\n",
       " 'College',\n",
       " 'Colnett',\n",
       " 'Cologne',\n",
       " 'Cologne-water',\n",
       " 'Colonies',\n",
       " 'Colossus',\n",
       " 'Columbus',\n",
       " 'Coming',\n",
       " 'Commanded',\n",
       " 'Commanders',\n",
       " 'Commend',\n",
       " 'Commodore',\n",
       " 'Commodores',\n",
       " 'Common',\n",
       " 'Commonly',\n",
       " 'Commons',\n",
       " 'Commonwealth',\n",
       " 'Companies',\n",
       " 'Comparing',\n",
       " 'Concerning',\n",
       " 'Congregation',\n",
       " 'Congregational',\n",
       " 'Conjuror',\n",
       " 'Connecticut',\n",
       " 'Consequently',\n",
       " 'Consider',\n",
       " 'Considering',\n",
       " 'Constable',\n",
       " 'Constantine',\n",
       " 'Constantinople',\n",
       " 'Consumptive',\n",
       " 'Continents',\n",
       " 'Contrasted',\n",
       " 'Conversation',\n",
       " 'Convulsively',\n",
       " 'Cooper',\n",
       " 'Coopman',\n",
       " 'Copenhagen',\n",
       " 'Coppered',\n",
       " 'Corinthians',\n",
       " 'Corkscrew',\n",
       " 'Corlaer',\n",
       " 'Corlears',\n",
       " 'Coronation',\n",
       " 'Corresponding',\n",
       " 'Corrupt',\n",
       " 'Counterpane',\n",
       " 'County',\n",
       " 'Cousin',\n",
       " 'Cowper',\n",
       " 'Crammer',\n",
       " 'Crappo',\n",
       " 'Crappoes',\n",
       " 'Crazed',\n",
       " 'Creagh',\n",
       " 'Created',\n",
       " 'Cretan',\n",
       " 'Crockett',\n",
       " 'Crossed',\n",
       " 'Crossing',\n",
       " 'Crotch',\n",
       " 'Crowding',\n",
       " 'Crozetts',\n",
       " 'Cruelty',\n",
       " 'Cruising',\n",
       " 'Cruppered',\n",
       " 'Crusaders',\n",
       " 'Crushed',\n",
       " 'Crying',\n",
       " 'Curious',\n",
       " 'Cursed',\n",
       " 'Curses',\n",
       " 'Cussed',\n",
       " 'Customs',\n",
       " 'Cutting',\n",
       " 'Cuvier',\n",
       " 'Cyclades',\n",
       " \"D'Wolf\",\n",
       " 'DAGGOO',\n",
       " 'DANCING',\n",
       " 'DANIEL',\n",
       " 'DANISH',\n",
       " 'DARKENS',\n",
       " 'DARWIN',\n",
       " 'DAVENANT',\n",
       " 'DEBELL',\n",
       " 'DESTROYED',\n",
       " 'DEVIL-DAM',\n",
       " 'DICTIONARY',\n",
       " 'DIGNITY',\n",
       " 'DISCOVERS',\n",
       " 'DISSECTION',\n",
       " 'DRYDEN',\n",
       " 'DUODECIMO',\n",
       " 'DUODECIMOES.',\n",
       " 'DURING',\n",
       " 'Daboll',\n",
       " 'Daggoo',\n",
       " 'Damocles',\n",
       " 'Dampier',\n",
       " 'Daniel',\n",
       " 'Danish',\n",
       " 'Dantean',\n",
       " \"Dar'st\",\n",
       " 'Dardanelles',\n",
       " 'Darien',\n",
       " 'Darkness',\n",
       " 'Darmonodes',\n",
       " 'Dashing',\n",
       " 'Dauphine',\n",
       " 'Deacon',\n",
       " 'Decanter',\n",
       " 'Decapitation',\n",
       " 'December',\n",
       " 'Deliberately',\n",
       " 'Delight',\n",
       " 'Delightful',\n",
       " 'Deliverer',\n",
       " 'Denderah',\n",
       " 'Depend',\n",
       " 'Derick',\n",
       " \"Derick's\",\n",
       " 'Dericks',\n",
       " 'Descartian',\n",
       " 'Descending',\n",
       " 'Desecrated',\n",
       " 'Desmarest',\n",
       " 'Desolation',\n",
       " 'Despairing',\n",
       " 'Despatch',\n",
       " 'Detached',\n",
       " 'Deuteronomy',\n",
       " 'Devil-dam',\n",
       " 'Devils',\n",
       " \"Dick's\",\n",
       " \"Did'st\",\n",
       " 'Diminish',\n",
       " 'Dinner',\n",
       " 'Dinting',\n",
       " 'Discovery',\n",
       " 'Disdain',\n",
       " 'Dismal',\n",
       " 'Dissect',\n",
       " 'Divine',\n",
       " 'Diving',\n",
       " 'Doctor',\n",
       " 'Dominic',\n",
       " 'Dorchester',\n",
       " 'Doubloon',\n",
       " 'Doubtless',\n",
       " 'Doubts',\n",
       " 'Dough-Boy',\n",
       " 'Dough-boy',\n",
       " 'Dragged',\n",
       " 'Dragon',\n",
       " 'Drawing',\n",
       " 'Drinking',\n",
       " 'Dropping',\n",
       " 'Dugongs',\n",
       " 'Dunder',\n",
       " 'Dunfermline',\n",
       " 'Dunkirk',\n",
       " 'Duodecimo',\n",
       " 'Duodecimoes',\n",
       " 'Durand',\n",
       " 'During',\n",
       " 'Dutchman',\n",
       " \"ECKERMANN'S\",\n",
       " 'ECUADOR',\n",
       " 'EDMUND',\n",
       " 'ELECTION',\n",
       " 'ELIZABETH',\n",
       " 'ELLERY',\n",
       " 'EMBONPOINT',\n",
       " 'ENGLISH',\n",
       " 'ENSUING',\n",
       " 'ERECTION',\n",
       " 'ERROMANGOAN',\n",
       " 'ESCAPED',\n",
       " 'ETCHINGS',\n",
       " 'ETYMOLOGY',\n",
       " 'EXCHANGE',\n",
       " 'EXCHANGING',\n",
       " 'EXTENDING',\n",
       " 'EXTRACTS',\n",
       " 'EZEKIEL',\n",
       " 'Earthsman',\n",
       " 'East-sou-east',\n",
       " 'East-south-east',\n",
       " 'Eastern',\n",
       " 'Ecclesiastes',\n",
       " 'Eckerman',\n",
       " 'Eddystone',\n",
       " 'Edgewise',\n",
       " 'Edmund',\n",
       " 'Edward',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehrenbreitstein',\n",
       " 'Either',\n",
       " 'Electors',\n",
       " 'Elephant',\n",
       " 'Elephanta',\n",
       " 'Elephants',\n",
       " 'Elijah',\n",
       " 'Ellenborough',\n",
       " 'Elsewhere',\n",
       " 'Emblazonings',\n",
       " 'Emboldened',\n",
       " 'Emperor',\n",
       " 'Emperors',\n",
       " 'Empire',\n",
       " 'Enderbies',\n",
       " 'Enderby',\n",
       " 'Enderbys',\n",
       " 'England',\n",
       " 'Englander',\n",
       " 'English',\n",
       " 'Englishman',\n",
       " 'Englishmen',\n",
       " 'Enough',\n",
       " 'Entering',\n",
       " 'Entreaties',\n",
       " 'Enveloped',\n",
       " 'Ephesian',\n",
       " 'Epilogue',\n",
       " 'Epitome',\n",
       " 'Equality',\n",
       " 'Equator',\n",
       " 'Equatorial',\n",
       " 'Erromanggoans',\n",
       " 'Erroneous',\n",
       " 'Erskine',\n",
       " 'Espied',\n",
       " 'Espying',\n",
       " 'Esquimaux',\n",
       " 'Eternities',\n",
       " 'Eternity',\n",
       " 'Ethiopian',\n",
       " 'Euclid',\n",
       " 'Euclidean',\n",
       " 'Euroclydon',\n",
       " 'Europa',\n",
       " 'Europe',\n",
       " 'European',\n",
       " 'Evangelist',\n",
       " 'Evangelists',\n",
       " 'Excellent',\n",
       " 'Excepting',\n",
       " 'Exception',\n",
       " 'Expedition',\n",
       " 'Expeditions',\n",
       " 'Explain',\n",
       " 'Exploring',\n",
       " 'Extending',\n",
       " 'Ezekiel',\n",
       " 'F-shaped',\n",
       " 'FAERIE',\n",
       " 'FALCONER',\n",
       " 'FAMOUS',\n",
       " 'FIGURED',\n",
       " 'FILING',\n",
       " 'FIN-BACK',\n",
       " 'FINALLY',\n",
       " 'FIRMLY',\n",
       " 'FISHERMAN',\n",
       " 'FISHERY',\n",
       " 'FLAMES',\n",
       " 'FLASHES',\n",
       " 'FOLIOS',\n",
       " 'FOLLOW',\n",
       " 'FOLLOWING',\n",
       " 'FORECASTLE',\n",
       " 'FORESAIL',\n",
       " 'FORWARD',\n",
       " 'FREDERICK',\n",
       " 'FRENCH',\n",
       " 'FROCK.',\n",
       " 'FULLLER',\n",
       " 'Faintly',\n",
       " 'Falsehood',\n",
       " 'Fanning',\n",
       " 'Farewell',\n",
       " 'Fashioned',\n",
       " 'Fast-Fish',\n",
       " 'Fasting',\n",
       " 'Fat-Cutter',\n",
       " 'Father',\n",
       " 'Fearing',\n",
       " 'February',\n",
       " 'Fedallah',\n",
       " 'Feegee',\n",
       " 'Feegeeans',\n",
       " 'Feegees',\n",
       " 'Fellow-critters',\n",
       " 'Ferdinando',\n",
       " 'Fernandes',\n",
       " 'Fields',\n",
       " 'Fiercely',\n",
       " 'Figuera',\n",
       " 'Fin-Back',\n",
       " 'Fin-Backs',\n",
       " 'Fin-back',\n",
       " 'Finally',\n",
       " 'Finding',\n",
       " 'Fisheries',\n",
       " 'Fishery',\n",
       " 'Fishes',\n",
       " 'Fishiest',\n",
       " 'Fleece',\n",
       " 'Floating',\n",
       " 'Floundered',\n",
       " 'Flounders',\n",
       " 'Flukes',\n",
       " 'Flying',\n",
       " 'Folding',\n",
       " 'Folger',\n",
       " 'Folgers',\n",
       " 'Folios',\n",
       " 'Foolish',\n",
       " 'Forced',\n",
       " 'Fore-Top',\n",
       " 'Forecastle',\n",
       " 'Forehead',\n",
       " 'Foremost',\n",
       " 'Forming',\n",
       " 'Formosa',\n",
       " 'Forthwith',\n",
       " 'Forty-barrel-bull',\n",
       " 'Forward',\n",
       " 'Fossil',\n",
       " 'Fountain',\n",
       " 'Fourth',\n",
       " 'Fourth-of-July',\n",
       " 'France',\n",
       " 'Frankfort',\n",
       " 'Franklin',\n",
       " 'Frederick',\n",
       " 'Free-Mason',\n",
       " 'Freely',\n",
       " 'Freeze',\n",
       " 'French',\n",
       " 'Frenchman',\n",
       " 'Frenchmen',\n",
       " 'Friend',\n",
       " 'Friends',\n",
       " 'Friesland',\n",
       " 'Frighted',\n",
       " 'Frobisher',\n",
       " 'Froissart',\n",
       " 'Funeral',\n",
       " 'Further',\n",
       " 'Furthermore',\n",
       " 'Future',\n",
       " 'GATHER',\n",
       " 'GATHERED',\n",
       " 'GAZING',\n",
       " 'GENERALLY',\n",
       " 'GENESIS',\n",
       " 'GOETHE',\n",
       " 'GOLDEN',\n",
       " 'GOLDSMITH',\n",
       " 'GONDIBERT',\n",
       " 'GRAMPUS',\n",
       " 'GREENLAND',\n",
       " 'GRIMLY',\n",
       " 'Gabriel',\n",
       " 'Gaining',\n",
       " 'Galleries',\n",
       " 'Gallipagos',\n",
       " 'Gamming',\n",
       " 'Ganders',\n",
       " 'Ganges',\n",
       " 'Gardiner',\n",
       " 'Garnery',\n",
       " 'Gather',\n",
       " 'Gay-Head',\n",
       " 'Gay-Header',\n",
       " 'Gay-Headers',\n",
       " 'Gayhead',\n",
       " 'Gazette',\n",
       " 'Gemini',\n",
       " 'General',\n",
       " 'Genesis',\n",
       " 'Geneva',\n",
       " 'Genius',\n",
       " 'Gentlemen',\n",
       " 'Gently',\n",
       " 'Geological',\n",
       " 'George',\n",
       " 'Germain',\n",
       " 'German',\n",
       " 'Germans',\n",
       " 'Gesner',\n",
       " 'Gibraltar',\n",
       " 'Gifted',\n",
       " 'Gilder',\n",
       " 'Ginger',\n",
       " 'Ginger-jub',\n",
       " 'Giving',\n",
       " 'Glacier',\n",
       " 'Glancing',\n",
       " 'Gliding',\n",
       " 'Glimpses',\n",
       " 'Gnawed',\n",
       " 'God-fugitive',\n",
       " 'God-omnipresent',\n",
       " 'Goethe',\n",
       " 'Golconda',\n",
       " 'Golden',\n",
       " 'Goldsmith',\n",
       " 'Gomorrah',\n",
       " 'Good-bye',\n",
       " 'Good-humored',\n",
       " 'Goodwin',\n",
       " 'Gospel',\n",
       " 'Gothic',\n",
       " 'Gracious',\n",
       " 'Grammar',\n",
       " 'Grampus',\n",
       " 'Grand-Lama-like',\n",
       " 'Granting',\n",
       " 'Grecian',\n",
       " 'Greece',\n",
       " 'Greedily',\n",
       " 'Greeks',\n",
       " 'Greenland',\n",
       " 'Greenlanders',\n",
       " 'Greenlandmen',\n",
       " 'Greenwich',\n",
       " 'Grenadier',\n",
       " 'Grisly',\n",
       " 'Ground',\n",
       " 'Grounds',\n",
       " 'Growlands',\n",
       " 'Guernsey-man',\n",
       " 'Guernseyman',\n",
       " 'Guinea',\n",
       " 'Guinea-coast',\n",
       " 'Gulfweed',\n",
       " 'HACKLUYT',\n",
       " 'HAMLET',\n",
       " 'HANGING',\n",
       " 'HARPOONEERS',\n",
       " 'HARRIS',\n",
       " 'HATCHWAY',\n",
       " 'HAVING',\n",
       " 'HAWTHORNE',\n",
       " 'HEIGHT',\n",
       " 'HERBERT',\n",
       " 'HEREABOUTS',\n",
       " 'HIMSELF',\n",
       " 'HISTORY',\n",
       " 'HOBBES',\n",
       " 'HOBOMACK',\n",
       " 'HOLLAND',\n",
       " 'HOMEWARD',\n",
       " 'HOMINUM',\n",
       " 'HORIZONTAL',\n",
       " 'HORRID',\n",
       " 'HUMP-BACK',\n",
       " 'HUMP-BACKED',\n",
       " 'HUNTER',\n",
       " 'HUSSEY',\n",
       " 'Haarlem',\n",
       " 'Hackluyt',\n",
       " 'Halloa',\n",
       " 'Halloo',\n",
       " 'Halting',\n",
       " 'Hampshire',\n",
       " 'Hampton',\n",
       " 'Handling',\n",
       " 'Hang-Ho',\n",
       " 'Hannibal',\n",
       " 'Hanoverian',\n",
       " 'Harbor',\n",
       " 'Hardicanutes',\n",
       " 'Hardly',\n",
       " 'Harmattans',\n",
       " 'Harold',\n",
       " 'Harpooneer',\n",
       " 'Harpoons',\n",
       " 'Harris',\n",
       " 'Harvard',\n",
       " 'Having',\n",
       " 'Hawaiian',\n",
       " 'Hay-Seed',\n",
       " 'Headed',\n",
       " 'Heading',\n",
       " 'Hearing',\n",
       " 'Hearkening',\n",
       " 'Heated',\n",
       " 'Heaven',\n",
       " \"Heaven's\",\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hedgehog',\n",
       " 'Heeva-Heeva',\n",
       " 'Heidelburgh',\n",
       " 'Helena',\n",
       " 'Herculaneum',\n",
       " 'Hercules',\n",
       " 'Hereby',\n",
       " 'Herein',\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    dist=nltk.FreqDist(text1)\n",
    "    token_filter = sorted([token for token, freq in dist.items() if len(token)>5 and freq<150])\n",
    "    return token_filter # Your answer here\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    dist = nltk.FreqDist(text1)\n",
    "    \n",
    "    return sorted([(token, len(token)) for token, freq in dist.items()], key=operator.itemgetter(1), reverse=True)[0] # Your answer here\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13715, 'the'),\n",
       " (6513, 'of'),\n",
       " (6010, 'and'),\n",
       " (4545, 'a'),\n",
       " (4515, 'to'),\n",
       " (3908, 'in'),\n",
       " (2978, 'that'),\n",
       " (2459, 'his'),\n",
       " (2196, 'it'),\n",
       " (2111, 'I')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    dist = nltk.FreqDist(text1)\n",
    "    \n",
    "    return sorted([(freq, token) for token, freq in dist.items() if token.isalpha() and freq>2000], key=operator.itemgetter(0), reverse=True) # Your answer here\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.88489646772229"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    \n",
    "    \n",
    "    return np.mean([len(nltk.word_tokenize(sent)) for sent in nltk.sent_tokenize(moby_raw)]) # Your answer here\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "def answer_eight():\n",
    "    \n",
    "    pos = nltk.pos_tag(text1)\n",
    "    dist = nltk.FreqDist([tag for (word, tag) in pos])\n",
    "    return sorted([(tag, freq) for tag, freq in dist.items() if tag!=','], key=operator.itemgetter(1), reverse=True)[:6] # Your answer here\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\hdeng8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "nltk.download('words')\n",
    "correct_spellings = words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    \n",
    "    return # Your answer here\n",
    "    \n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    \n",
    "    return # Your answer here\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    \n",
    "    return # Your answer here \n",
    "    \n",
    "answer_eleven()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
